{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torchvision import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Do Not Touch This Cell\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "  \n",
    "    def forward(self, x):\n",
    "    \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on CPU...\n"
     ]
    }
   ],
   "source": [
    "##Do Not Touch This Cell\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=.01,\n",
    "                      momentum=0.5)\n",
    "if device =='cuda':\n",
    "    print(\"Train on GPU...\")\n",
    "else:\n",
    "    print(\"Train on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22ab2d25030>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Do Not Touch This Cell\n",
    "\n",
    "max_epochs = 30\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1\n",
    "\n",
    "\n",
    "random_seed = 671\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST('mnist_data', train=True, download=True,\n",
    "         transform=torchvision.transforms.ToTensor())\n",
    "        \n",
    "test_set =  datasets.MNIST('mnist_data', train=False, download=True,\n",
    "         transform=torchvision.transforms.ToTensor())\n",
    "                           \n",
    "all_MNIST = train_set + test_set\n",
    "\n",
    "##TODO: Split the set into 50% train, 50% test (there are 70K total images)\n",
    "train_amt = int(len(all_MNIST) * 0.5)\n",
    "test_amt = len(all_MNIST) - train_amt\n",
    "train_set, test_set = random_split(all_MNIST,[train_amt, test_amt])\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set, batch_size=batch_size_test, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Implement Training Loop\n",
    "##Make sure to keep track of avg epoch losses in lists\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "def train(net):\n",
    "    losses = []\n",
    "    \n",
    "    #TODO: set net to train mode\n",
    "    net.train()\n",
    "    for epoch in range(max_epochs):\n",
    "        print('Epoch:', epoch + 1)\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            ##TODO: pass the data into the network and store the output \n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = net(data)\n",
    "            ##TODO: Calculate the negative log likelihood between the output and target \n",
    "            loss = criterion(outputs, target)\n",
    "            \n",
    "            ##TODO: Perform backpropagation \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            ##TODO: Add the loss to epoch_loss.\n",
    "            ##HINT: the loss variable is currently a tensor. Use loss.item() \n",
    "            ##to get the scalar value\n",
    "            epoch_loss += loss\n",
    "            \n",
    "        #TODO: append average epoch loss to losses list  \n",
    "        avg_loss = epoch_loss / (batch_idx + 1)\n",
    "        print(avg_loss)\n",
    "        losses.append(avg_loss)\n",
    "            \n",
    "            \n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "tensor(0.6263, grad_fn=<DivBackward0>)\n",
      "Epoch: 2\n",
      "tensor(0.2244, grad_fn=<DivBackward0>)\n",
      "Epoch: 3\n",
      "tensor(0.1646, grad_fn=<DivBackward0>)\n",
      "Epoch: 4\n",
      "tensor(0.1336, grad_fn=<DivBackward0>)\n",
      "Epoch: 5\n",
      "tensor(0.1117, grad_fn=<DivBackward0>)\n",
      "Epoch: 6\n",
      "tensor(0.0981, grad_fn=<DivBackward0>)\n",
      "Epoch: 7\n",
      "tensor(0.0866, grad_fn=<DivBackward0>)\n",
      "Epoch: 8\n",
      "tensor(0.0790, grad_fn=<DivBackward0>)\n",
      "Epoch: 9\n",
      "tensor(0.0691, grad_fn=<DivBackward0>)\n",
      "Epoch: 10\n",
      "tensor(0.0630, grad_fn=<DivBackward0>)\n",
      "Epoch: 11\n",
      "tensor(0.0567, grad_fn=<DivBackward0>)\n",
      "Epoch: 12\n",
      "tensor(0.0512, grad_fn=<DivBackward0>)\n",
      "Epoch: 13\n",
      "tensor(0.0469, grad_fn=<DivBackward0>)\n",
      "Epoch: 14\n",
      "tensor(0.0429, grad_fn=<DivBackward0>)\n",
      "Epoch: 15\n",
      "tensor(0.0379, grad_fn=<DivBackward0>)\n",
      "Epoch: 16\n",
      "tensor(0.0348, grad_fn=<DivBackward0>)\n",
      "Epoch: 17\n",
      "tensor(0.0307, grad_fn=<DivBackward0>)\n",
      "Epoch: 18\n",
      "tensor(0.0285, grad_fn=<DivBackward0>)\n",
      "Epoch: 19\n",
      "tensor(0.0242, grad_fn=<DivBackward0>)\n",
      "Epoch: 20\n",
      "tensor(0.0230, grad_fn=<DivBackward0>)\n",
      "Epoch: 21\n",
      "tensor(0.0207, grad_fn=<DivBackward0>)\n",
      "Epoch: 22\n",
      "tensor(0.0186, grad_fn=<DivBackward0>)\n",
      "Epoch: 23\n",
      "tensor(0.0169, grad_fn=<DivBackward0>)\n",
      "Epoch: 24\n",
      "tensor(0.0160, grad_fn=<DivBackward0>)\n",
      "Epoch: 25\n",
      "tensor(0.0140, grad_fn=<DivBackward0>)\n",
      "Epoch: 26\n",
      "tensor(0.0123, grad_fn=<DivBackward0>)\n",
      "Epoch: 27\n",
      "tensor(0.0107, grad_fn=<DivBackward0>)\n",
      "Epoch: 28\n",
      "tensor(0.0086, grad_fn=<DivBackward0>)\n",
      "Epoch: 29\n",
      "tensor(0.0086, grad_fn=<DivBackward0>)\n",
      "Epoch: 30\n",
      "tensor(0.0064, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "losses = train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19252/1226427834.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m##Make sure to label axes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3018\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3019\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   3020\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \"\"\"\n\u001b[0;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\matplotlib\\cbook\\__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1337\u001b[0m     \u001b[1;34m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1339\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1340\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[0mary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##TODO: Plot losses\n",
    "##Make sure to label axes\n",
    "x = np.linspace(1, len(losses), num=len(losses))\n",
    "plt.plot(x, losses)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When does the network start to converge?\n",
    "\n",
    "\n",
    "The network starts to converge in about epoch 10 to 15. \n",
    "In these epoches, the loss decreases, so the loss is 0.1 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Test on the test set and get the confusion matrix\n",
    "\n",
    "def get_confusion_matrix(net):\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    #TODO: set network to evaluation mode\n",
    "    net.eval()\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            ##TODO: pass the data into the network and update predictions and target list\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(data)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            ##TODO: update predictions list and targets list\n",
    "            predictions.append(predicted)\n",
    "            targets.append(target)\n",
    "        \n",
    "            if batch_idx % 5000 == 0:\n",
    "                print('Finished Image #', batch_idx)\n",
    "\n",
    "    predictions = [element.cpu().numpy() for element in predictions]\n",
    "    predictions = np.asarray(predictions).flatten()\n",
    "    targets = [element.cpu().numpy() for element in targets]\n",
    "    targets = np.asarray(targets).flatten() \n",
    "    \n",
    "    return confusion_matrix(targets, predictions), np.array(predictions), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix_train(net):\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    #TODO: set network to evaluation mode\n",
    "    net.eval()\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            ##TODO: pass the data into the network and update predictions and target list\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            # Generate output from the DNN.\n",
    "            outputs = net(data)\n",
    "            _, predicted = outputs.max(1)\n",
    "            ##TODO: update predictions list and targets list\n",
    "            for item in predicted.cpu().numpy():\n",
    "                predictions.append(item)\n",
    "            for item in target.cpu().numpy():\n",
    "                targets.append(item)\n",
    "        \n",
    "            if batch_idx % 5000 == 0:\n",
    "                print('Finished Image #', batch_idx)\n",
    "\n",
    "    predictions = np.asarray(predictions).flatten()\n",
    "    targets = np.asarray(targets).flatten()\n",
    "    \n",
    "    return confusion_matrix(targets, predictions), np.array(predictions), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Image # 0\n",
      "Finished Image # 5000\n",
      "Finished Image # 10000\n",
      "Finished Image # 15000\n",
      "Finished Image # 20000\n",
      "Finished Image # 25000\n",
      "Finished Image # 30000\n",
      "test confusion matrix:\n",
      "[[3441    4    3    0    0    5    5    4   21    6]\n",
      " [   0 3950    2    2    0    0    2    5    4    3]\n",
      " [  13   10 3413   11    4    1    3   22   19    4]\n",
      " [   5   10   21 3475    0   19    1   11   26   12]\n",
      " [   3   15    5    0 3345    1   12    4    7   35]\n",
      " [   3    2    2    8    0 3090   13    1   16   15]\n",
      " [  13    4    1    1    6    4 3347    0   10    0]\n",
      " [   1   12   16    6    5    0    0 3571    6   22]\n",
      " [   5   21    4   11    4   15    7    5 3302   13]\n",
      " [   4    5    1   14   14    9    2   23   11 3391]]\n",
      "\n",
      "Finished Image # 0\n",
      "train confusion matrix:\n",
      "[[3414    0    0    0    0    0    0    0    0    0]\n",
      " [   0 3908    0    0    0    0    0    1    0    0]\n",
      " [   1    2 3483    0    0    0    0    4    0    0]\n",
      " [   0    0    0 3556    0    0    0    1    4    0]\n",
      " [   0    1    0    0 3391    0    0    0    0    5]\n",
      " [   0    0    0    3    0 3159    1    0    0    0]\n",
      " [   1    1    0    0    0    0 3488    0    0    0]\n",
      " [   0    2    0    0    0    0    0 3649    1    2]\n",
      " [   0    4    0    1    0    0    0    1 3432    0]\n",
      " [   2    1    0    0    0    0    0    5    3 3473]]\n"
     ]
    }
   ],
   "source": [
    "##TODO: print Confusion matrix\n",
    "confusion, predictions, targets = get_confusion_matrix(net)\n",
    "print('test confusion matrix:')\n",
    "print(confusion)\n",
    "print()\n",
    "confusion, predictions_train, targets_train = get_confusion_matrix_train(net)\n",
    "print('train confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy = 0.9807142857142858\n",
      "Training Accuracy = 0.9986571428571429\n"
     ]
    }
   ],
   "source": [
    "##TODO: Compute Accuracy\n",
    "correct_examples = (predictions == targets).sum()\n",
    "acc = correct_examples / len(predictions)\n",
    "print('Testing Accuracy =', acc)\n",
    "\n",
    "correct_examples = (predictions_train == targets_train).sum()\n",
    "acc = correct_examples / len(predictions)\n",
    "print('Training Accuracy =', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which images seems to get confused the most? Intiutively, why does that make sense?\n",
    "\n",
    "The image of 5 is the most confused one. In my opinion, it was confused because the shape of 5 is similar to 6 or 9.\n",
    "The machine couldn't classify it very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##For convenience, here is the dataset in flattened numpy arrays for the rest of problem\n",
    "\n",
    "trainset_list = list(zip(*train_set))\n",
    "X_train = np.array([trainset_list[0][index].numpy().flatten() for index in range(train_amt)])\n",
    "\n",
    "Y_train = np.array([trainset_list[1][index] for index in range(train_amt)])\n",
    "\n",
    "testset_list = list(zip(*test_set))\n",
    "X_test = np.array([testset_list[0][index].numpy().flatten() for index in range(test_amt)])\n",
    "\n",
    "Y_test = np.array([testset_list[1][index] for index in range(test_amt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish training logistic regression .....\n"
     ]
    }
   ],
   "source": [
    "##TODO: Fit a logistic regression model on the training set\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=10000).fit(X_train, Y_train)\n",
    "predicted_test = clf.predict(X_test)\n",
    "\n",
    "predicted_train = clf.predict(X_train)\n",
    "\n",
    "print('Finish training logistic regression .....')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.9439142857142857\n",
      "train confusion matrix:\n",
      "[[3351    0    8    3    7   17   14    1   12    1]\n",
      " [   1 3827   14   13    4   10    1    8   24    7]\n",
      " [   9   25 3229   40   31   16   29   27   73   11]\n",
      " [   4   12   66 3276    3   97    4   22   49   28]\n",
      " [   6    8   11    3 3240    4   22    6   18   79]\n",
      " [  18   11   20   85   30 2866   42    9   68   14]\n",
      " [  11    7   14    2   15   39 3392    2    8    0]\n",
      " [   1    8   31   13   18    5    2 3480    6   90]\n",
      " [   8   45   31   64    5   75   24    8 3145   33]\n",
      " [  16   16   10   34   65   13    0   76   23 3231]]\n",
      "\n",
      "Testing Accuracy = 0.919\n",
      "test confusion matrix:\n",
      "[[3345    1   13   11    7   26   36   11   30    9]\n",
      " [   0 3868   18    7    1   18    4    7   38    7]\n",
      " [  25   36 3139   48   47   13   52   47   78   15]\n",
      " [  16   22   83 3181    3  118   14   30   72   41]\n",
      " [   2   24   23    7 3189    4   28   13   27  110]\n",
      " [  33   21   31   92   30 2758   50   12   85   38]\n",
      " [  22    9   37    0   27   57 3212    7   14    1]\n",
      " [   8   16   43   22   37    4    2 3371   16  120]\n",
      " [  31   68   48   89   17   88   36   12 2947   51]\n",
      " [  11   14    9   51   85   24    2   94   29 3155]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##TODO: For both the training and test set, get their confusion matrices and accuracies\n",
    "\n",
    "confusion_train = confusion_matrix(Y_train, predicted_train)\n",
    "correct_examples = (predicted_train == Y_train).sum()\n",
    "acc = correct_examples / len(predictions)\n",
    "print('Training Accuracy =', acc)\n",
    "print('train confusion matrix:')\n",
    "print(confusion_train)\n",
    "print()\n",
    "confusion_test = confusion_matrix(Y_test, predicted_test)\n",
    "correct_examples = (predicted_test == Y_test).sum()\n",
    "acc = correct_examples / len(predictions)\n",
    "print('Testing Accuracy =', acc)\n",
    "print('test confusion matrix:')\n",
    "print(confusion_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is  it overfitting?  Does it get confused on the same images?\n",
    "\n",
    "\n",
    "Yes, it is. The model is likely to overfit. Also, this model get confused on the image of 5 like the previous NeuralNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Run Kmeans clustering (k = 10) on TEST set\n",
    "##Use random restarts, 5 restarts is fine, choose solution with lowest k-means objective\n",
    "##Assign each cluster to the class with the majority label\n",
    "best_inertia = 10**10\n",
    "final_model = None\n",
    "for _ in range(5):\n",
    "    kmeans = KMeans(n_clusters=10, max_iter=10000, init='random').fit(X_test)\n",
    "#     print(kmeans.inertia_)\n",
    "    if kmeans.inertia_ < best_inertia:\n",
    "        best_inertia = kmeans.inertia_\n",
    "        final_model = kmeans\n",
    "predicted = np.array(final_model.labels_)\n",
    "cluster = np.zeros([10, 10])\n",
    "for i in range(len(final_model.labels_)):\n",
    "    clus = final_model.labels_[i]\n",
    "    class_true = Y_test[i]\n",
    "    cluster[clus][class_true] += 1\n",
    "assign_cluster = np.argmax(cluster, axis=1)\n",
    "# print(assign_cluster.shape)\n",
    "# print(assign_cluster)\n",
    "for i in range(len(predicted)):\n",
    "    predicted[i] = assign_cluster[predicted[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy = 0.5832857142857143\n",
      "test confusion matrix:\n",
      "[[2481    5    3  146   26  671  104    4   49    0]\n",
      " [   0 3941    1    6    0    3    4    6    7    0]\n",
      " [  30  413 2460  171  109  116   77   36   88    0]\n",
      " [  11  271   88 2309   98  257   17   28  501    0]\n",
      " [   4  208   18    0 1846  127   77 1136   11    0]\n",
      " [  23  241    4 1051  220  874   33  112  592    0]\n",
      " [  39  142   32   20   35  866 2241    3    8    0]\n",
      " [  13  354   30    2  999    6    4 2222    9    0]\n",
      " [  20  328   31  515  111  210   27  104 2041    0]\n",
      " [  16  156    9   46 1685   23    8 1484   47    0]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##TODO: Get confusion matrix and accuracy again\n",
    "confusion_test = confusion_matrix(Y_test, predicted)\n",
    "correct_examples = (predicted == Y_test).sum()\n",
    "acc = correct_examples / len(predictions)\n",
    "print('Testing Accuracy =', acc)\n",
    "print('test confusion matrix:')\n",
    "print(confusion_test)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does its performance compare to the other methods? \n",
    "\n",
    "K means is the model that performed the worst with 58.3% testing accuracy. Non-classification of the image of 9 is likely to cause the bad performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
